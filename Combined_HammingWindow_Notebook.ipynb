{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1684a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import glob\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import soundfile as sf \n",
    "import sys\n",
    "import librosa \n",
    "import librosa.display\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Audio\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f147b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "578037d8",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5f59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming Window\n",
    "# Set paths\n",
    "home = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Baseline_Shortened_Cropped/\"\n",
    "destination = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Hamming_Shortened_Cropped/\"\n",
    "\n",
    "# Get list of all files in home directory\n",
    "homeList = os.listdir(home)\n",
    "\n",
    "# Loop through all files in home directory\n",
    "for dir in homeList:\n",
    "    # Load audio file\n",
    "    signal, sr = librosa.load(home + dir)\n",
    "    \n",
    "    # Calculate window length and hop length\n",
    "    window_length = int(sr * 0.025) # 25ms window length\n",
    "    hop_length = int(sr * 0.010) # 10ms hop length\n",
    "    \n",
    "    # Create Hamming window\n",
    "    hamming_window = hamming(window_length)\n",
    "    \n",
    "    # Pad signal to ensure it can be split into frames without overlap\n",
    "    n_frames = int(np.ceil(len(signal) / hop_length))\n",
    "    signal_length = n_frames * hop_length\n",
    "    padding = signal_length - len(signal)\n",
    "    signal_padded = np.pad(signal, (0, padding), 'constant', constant_values=0)\n",
    "    \n",
    "    # Apply Hamming window to signal using overlapping frames\n",
    "    frames = librosa.util.frame(signal_padded, frame_length=window_length, hop_length=hop_length)\n",
    "    windowed_frames = frames * hamming_window[:, np.newaxis]\n",
    "    signal_hamming = np.zeros(len(signal_padded))\n",
    "    for i in range(frames.shape[1]):\n",
    "        start = i * hop_length\n",
    "        end = start + window_length\n",
    "        signal_hamming[start:end] += windowed_frames[:, i]\n",
    "    signal_hamming = signal_hamming[:len(signal)]\n",
    "    \n",
    "    # Save the modified audio file to destination directory\n",
    "    savePath = destination + dir\n",
    "    sf.write(savePath, signal_hamming, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab50f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extract MFCC\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data = []\n",
    "label = []\n",
    "Path = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Hamming_Shortened_Cropped/\"\n",
    "files = [f for f in listdir(Path) if isfile(join(Path, f))]\n",
    "for x in files:\n",
    "    filePath = Path + x\n",
    "    label.append(x[0])\n",
    "    signal, sr = librosa.load(filePath, sr=None)\n",
    "    #mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length = 256, n_mfcc = 20) \n",
    "    mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length = 256, n_mfcc = 18) \n",
    "    #mfcc_1d = np.ravel(mfcc)\n",
    "    data.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0694df16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 18, 259)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e4bb41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 18, 259, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.expand_dims(data, axis=3)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3b26408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_new = []\n",
    "for i in range(len(label)):\n",
    "    if label[i] == 'n': #Neutral\n",
    "        x=3\n",
    "    elif label[i] == 'h': #Happy\n",
    "        x=0\n",
    "    elif label[i] == 's': #S\n",
    "        x=1\n",
    "    elif label[i] == 'a': #Angry\n",
    "        x = 2\n",
    "    label_new.append(x)\n",
    "\n",
    "#print(label_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eb3a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, label_new, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "553d9cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793, 18, 259, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(x_train)\n",
    "X_test = np.array(x_test)\n",
    "Y_train = np.array(y_train)\n",
    "Y_test = np.array(y_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf69087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 18, 259, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 18, 259, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 18, 259, 64)       36928     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 18, 259, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 129, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 9, 129, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 9, 129, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 9, 129, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 9, 129, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 9, 129, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 64, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4, 64, 128)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               16777728  \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,042,372\n",
      "Trainable params: 17,040,580\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This model gives 62% with 30 mfccs, 75.6% for 18 mfccs\n",
    "# change epochs from 20 - 24\n",
    "model = Sequential()\n",
    "from keras.layers import BatchNormalization\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(18, 259, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c62f779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 113s 4s/step - loss: 1.5021 - accuracy: 0.4741 - val_loss: 26.8977 - val_accuracy: 0.2965\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 105s 4s/step - loss: 0.9346 - accuracy: 0.6381 - val_loss: 12.2759 - val_accuracy: 0.3719\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.7727 - accuracy: 0.6986 - val_loss: 8.2981 - val_accuracy: 0.2764\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 90s 4s/step - loss: 0.5888 - accuracy: 0.7806 - val_loss: 3.9626 - val_accuracy: 0.3518\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.4874 - accuracy: 0.8108 - val_loss: 4.2884 - val_accuracy: 0.3266\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.3481 - accuracy: 0.8752 - val_loss: 2.3770 - val_accuracy: 0.4372\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 93s 4s/step - loss: 0.2764 - accuracy: 0.9067 - val_loss: 1.5224 - val_accuracy: 0.5276\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 87s 3s/step - loss: 0.2699 - accuracy: 0.9016 - val_loss: 1.5767 - val_accuracy: 0.5377\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 94s 4s/step - loss: 0.2528 - accuracy: 0.9004 - val_loss: 1.0393 - val_accuracy: 0.6683\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 90s 4s/step - loss: 0.1831 - accuracy: 0.9395 - val_loss: 1.1130 - val_accuracy: 0.6382\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.1450 - accuracy: 0.9483 - val_loss: 1.7493 - val_accuracy: 0.6181\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.0938 - accuracy: 0.9672 - val_loss: 1.0545 - val_accuracy: 0.6734\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 96s 4s/step - loss: 0.1202 - accuracy: 0.9571 - val_loss: 1.1166 - val_accuracy: 0.6734\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 1.1118 - val_accuracy: 0.7236\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 112s 5s/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 1.1497 - val_accuracy: 0.6784\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.0514 - accuracy: 0.9849 - val_loss: 0.8515 - val_accuracy: 0.7337\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.0614 - accuracy: 0.9786 - val_loss: 1.2150 - val_accuracy: 0.6633\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.0686 - accuracy: 0.9760 - val_loss: 1.3376 - val_accuracy: 0.6432\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0630 - accuracy: 0.9786 - val_loss: 1.2831 - val_accuracy: 0.6784\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 81s 3s/step - loss: 0.0797 - accuracy: 0.9760 - val_loss: 1.1539 - val_accuracy: 0.7186\n"
     ]
    }
   ],
   "source": [
    "# Train and Test Model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=32 , epochs= 20 , verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b09bbce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 687ms/step\n",
      "Precision: 0.7341773804085362\n",
      "Recall: 0.7185929648241206\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "# Get the predicted probabilities for the validation set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Compute precision and recall using scikit-learn metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(Y_test, y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "\n",
    "# Pre-Emphasis\n",
    "# Pre-Emphasis + Windowing: Precision: 77.97% Recall: 75.37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e4005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 676ms/step - loss: 1.1539 - accuracy: 0.7186\n",
      "Accuracy of our model on test data :  71.85929417610168 %\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (24,) and (20,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m fig\u001b[38;5;241m.\u001b[39mset_size_inches(\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(epochs , test_loss , label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining & Testing Loss: Hamming Window\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (24,) and (20,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(X_test,Y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(24)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(24,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss: Hamming Window')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy: Hamming Window')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# define y_true as the one-hot encoded version of the test labels\n",
    "y_true = np.zeros((len(y_test), 4)) # 4 is the number of emotions being classified\n",
    "y_true[np.arange(len(y_test)), y_test] = 1\n",
    "\n",
    "# convert y_pred from probabilities to class labels\n",
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# define y_pred as the one-hot encoded version of the predicted labels\n",
    "y_pred = np.zeros((len(predicted_labels), 4)) # 4 is the number of emotions being classified\n",
    "y_pred[np.arange(len(predicted_labels)), predicted_labels] = 1\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1), normalize='true')\n",
    "labels = ['Happy', 'Sad', 'Angry', 'Neutral'] # replace with your own emotion labels\n",
    "\n",
    "# plot the confusion matrix as a heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "# add axis labels and title\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix: Pre-Emphasis + Windowing')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ec39372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 81s 3s/step - loss: 1.5875 - accuracy: 0.4527 - val_loss: 44.7870 - val_accuracy: 0.2161\n",
      "7/7 [==============================] - 5s 693ms/step - loss: 44.7870 - accuracy: 0.2161\n",
      "1\n",
      "Epoch 1/2\n",
      "25/25 [==============================] - 112s 4s/step - loss: 0.8988 - accuracy: 0.6520 - val_loss: 14.7401 - val_accuracy: 0.3518\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 106s 4s/step - loss: 0.7094 - accuracy: 0.7289 - val_loss: 7.5212 - val_accuracy: 0.3568\n",
      "7/7 [==============================] - 6s 848ms/step - loss: 7.5212 - accuracy: 0.3568\n",
      "2\n",
      "Epoch 1/3\n",
      "25/25 [==============================] - 92s 4s/step - loss: 0.5498 - accuracy: 0.8146 - val_loss: 5.5013 - val_accuracy: 0.3467\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.4984 - accuracy: 0.8108 - val_loss: 7.2135 - val_accuracy: 0.2211\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 77s 3s/step - loss: 0.3436 - accuracy: 0.8701 - val_loss: 2.2239 - val_accuracy: 0.4724\n",
      "7/7 [==============================] - 4s 607ms/step - loss: 2.2239 - accuracy: 0.4724\n",
      "3\n",
      "Epoch 1/4\n",
      "25/25 [==============================] - 75s 3s/step - loss: 0.2407 - accuracy: 0.9180 - val_loss: 1.0119 - val_accuracy: 0.7085\n",
      "Epoch 2/4\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.1674 - accuracy: 0.9369 - val_loss: 0.8703 - val_accuracy: 0.6683\n",
      "Epoch 3/4\n",
      "25/25 [==============================] - 79s 3s/step - loss: 0.1597 - accuracy: 0.9407 - val_loss: 1.3207 - val_accuracy: 0.6533\n",
      "Epoch 4/4\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.1383 - accuracy: 0.9622 - val_loss: 1.2999 - val_accuracy: 0.7035\n",
      "7/7 [==============================] - 4s 619ms/step - loss: 1.2999 - accuracy: 0.7035\n",
      "4\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 78s 3s/step - loss: 0.0940 - accuracy: 0.9685 - val_loss: 1.1503 - val_accuracy: 0.6784\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 102s 4s/step - loss: 0.0773 - accuracy: 0.9710 - val_loss: 1.0368 - val_accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0692 - accuracy: 0.9811 - val_loss: 1.1294 - val_accuracy: 0.6683\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.0557 - accuracy: 0.9836 - val_loss: 1.2458 - val_accuracy: 0.6482\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.0593 - accuracy: 0.9786 - val_loss: 1.1324 - val_accuracy: 0.7286\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 1.1324 - accuracy: 0.7286\n",
      "5\n",
      "Epoch 1/6\n",
      "25/25 [==============================] - 75s 3s/step - loss: 0.0633 - accuracy: 0.9798 - val_loss: 1.0737 - val_accuracy: 0.7387\n",
      "Epoch 2/6\n",
      "25/25 [==============================] - 96s 4s/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 1.8696 - val_accuracy: 0.6583\n",
      "Epoch 3/6\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.0669 - accuracy: 0.9811 - val_loss: 2.1002 - val_accuracy: 0.6030\n",
      "Epoch 4/6\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 1.2250 - val_accuracy: 0.7437\n",
      "Epoch 5/6\n",
      "25/25 [==============================] - 68s 3s/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 1.5179 - val_accuracy: 0.7035\n",
      "Epoch 6/6\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 1.2067 - val_accuracy: 0.7286\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 1.2067 - accuracy: 0.7286\n",
      "6\n",
      "Epoch 1/8\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0527 - accuracy: 0.9887 - val_loss: 1.4209 - val_accuracy: 0.6784\n",
      "Epoch 2/8\n",
      "25/25 [==============================] - 68s 3s/step - loss: 0.0388 - accuracy: 0.9861 - val_loss: 1.3386 - val_accuracy: 0.6734\n",
      "Epoch 3/8\n",
      "25/25 [==============================] - 72s 3s/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 1.3533 - val_accuracy: 0.6834\n",
      "Epoch 4/8\n",
      "25/25 [==============================] - 73s 3s/step - loss: 0.0241 - accuracy: 0.9975 - val_loss: 1.3144 - val_accuracy: 0.6935\n",
      "Epoch 5/8\n",
      "25/25 [==============================] - 110s 4s/step - loss: 0.0164 - accuracy: 0.9987 - val_loss: 1.1494 - val_accuracy: 0.7437\n",
      "Epoch 6/8\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.0239 - val_accuracy: 0.7789\n",
      "Epoch 7/8\n",
      "25/25 [==============================] - 119s 5s/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 1.1924 - val_accuracy: 0.7437\n",
      "Epoch 8/8\n",
      "25/25 [==============================] - 126s 5s/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 1.4358 - val_accuracy: 0.6884\n",
      "7/7 [==============================] - 7s 969ms/step - loss: 1.4358 - accuracy: 0.6884\n",
      "7\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 113s 5s/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 1.2441 - val_accuracy: 0.7136\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 108s 4s/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 1.0781 - val_accuracy: 0.7638\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 118s 5s/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 1.2392 - val_accuracy: 0.7337\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 104s 4s/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 1.3525 - val_accuracy: 0.7538\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 109s 4s/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 1.4550 - val_accuracy: 0.7136\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 90s 4s/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 1.8058 - val_accuracy: 0.6734\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 95s 4s/step - loss: 0.0790 - accuracy: 0.9723 - val_loss: 1.8728 - val_accuracy: 0.6432\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 98s 4s/step - loss: 0.0587 - accuracy: 0.9798 - val_loss: 2.4264 - val_accuracy: 0.5980\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.0764 - accuracy: 0.9748 - val_loss: 1.4561 - val_accuracy: 0.6985\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.0581 - accuracy: 0.9823 - val_loss: 1.5108 - val_accuracy: 0.7085\n",
      "7/7 [==============================] - 5s 710ms/step - loss: 1.5108 - accuracy: 0.7085\n",
      "8\n",
      "Epoch 1/14\n",
      "25/25 [==============================] - 89s 4s/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 3.7749 - val_accuracy: 0.5025\n",
      "Epoch 2/14\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0517 - accuracy: 0.9798 - val_loss: 1.8918 - val_accuracy: 0.6683\n",
      "Epoch 3/14\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 1.3404 - val_accuracy: 0.7136\n",
      "Epoch 4/14\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 1.3395 - val_accuracy: 0.7538\n",
      "Epoch 5/14\n",
      "25/25 [==============================] - 84s 3s/step - loss: 0.0337 - accuracy: 0.9874 - val_loss: 1.3372 - val_accuracy: 0.7538\n",
      "Epoch 6/14\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 1.1372 - val_accuracy: 0.7638\n",
      "Epoch 7/14\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 1.1508 - val_accuracy: 0.7688\n",
      "Epoch 8/14\n",
      "25/25 [==============================] - 79s 3s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2359 - val_accuracy: 0.7538\n",
      "Epoch 9/14\n",
      "25/25 [==============================] - 105s 4s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.7487\n",
      "Epoch 10/14\n",
      "25/25 [==============================] - 101s 4s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.3122 - val_accuracy: 0.7638\n",
      "Epoch 11/14\n",
      "25/25 [==============================] - 142s 6s/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 1.2068 - val_accuracy: 0.7538\n",
      "Epoch 12/14\n",
      "25/25 [==============================] - 111s 4s/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 1.2459 - val_accuracy: 0.7437\n",
      "Epoch 13/14\n",
      "25/25 [==============================] - 116s 5s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.3057 - val_accuracy: 0.7186\n",
      "Epoch 14/14\n",
      "25/25 [==============================] - 132s 5s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1788 - val_accuracy: 0.7588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 772ms/step - loss: 1.1788 - accuracy: 0.7588\n",
      "9\n",
      "Epoch 1/16\n",
      "25/25 [==============================] - 135s 5s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.7437\n",
      "Epoch 2/16\n",
      "25/25 [==============================] - 136s 6s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.7789\n",
      "Epoch 3/16\n",
      "25/25 [==============================] - 141s 6s/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.4156 - val_accuracy: 0.7437\n",
      "Epoch 4/16\n",
      "25/25 [==============================] - 139s 6s/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 1.2737 - val_accuracy: 0.7588\n",
      "Epoch 5/16\n",
      "25/25 [==============================] - 40985s 1708s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1824 - val_accuracy: 0.7286\n",
      "Epoch 6/16\n",
      "25/25 [==============================] - 106s 4s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3110 - val_accuracy: 0.7085\n",
      "Epoch 7/16\n",
      "25/25 [==============================] - 106s 4s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2634 - val_accuracy: 0.7437\n",
      "Epoch 8/16\n",
      "25/25 [==============================] - 109s 4s/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.2689 - val_accuracy: 0.7437\n",
      "Epoch 9/16\n",
      "25/25 [==============================] - 105s 4s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2806 - val_accuracy: 0.7688\n",
      "Epoch 10/16\n",
      "25/25 [==============================] - 132s 5s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.7387\n",
      "Epoch 11/16\n",
      "25/25 [==============================] - 101s 4s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2505 - val_accuracy: 0.7487\n",
      "Epoch 12/16\n",
      "25/25 [==============================] - 96s 4s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2689 - val_accuracy: 0.7638\n",
      "Epoch 13/16\n",
      "25/25 [==============================] - 95s 4s/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 1.3076 - val_accuracy: 0.7387\n",
      "Epoch 14/16\n",
      "25/25 [==============================] - 96s 4s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.7538\n",
      "Epoch 15/16\n",
      "25/25 [==============================] - 93s 4s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3147 - val_accuracy: 0.7437\n",
      "Epoch 16/16\n",
      "25/25 [==============================] - 106s 4s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3082 - val_accuracy: 0.7638\n",
      "7/7 [==============================] - 7s 945ms/step - loss: 1.3082 - accuracy: 0.7638\n",
      "10\n",
      "Epoch 1/18\n",
      "25/25 [==============================] - 111s 4s/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 1.2695 - val_accuracy: 0.7538\n",
      "Epoch 2/18\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 1.3712 - val_accuracy: 0.7588\n",
      "Epoch 3/18\n",
      "25/25 [==============================] - 69s 3s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.3530 - val_accuracy: 0.7588\n",
      "Epoch 4/18\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.8017 - val_accuracy: 0.7136\n",
      "Epoch 5/18\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.7318 - val_accuracy: 0.6935\n",
      "Epoch 6/18\n",
      "25/25 [==============================] - 75s 3s/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.5240 - val_accuracy: 0.7286\n",
      "Epoch 7/18\n",
      "25/25 [==============================] - 6659s 3s/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 1.8433 - val_accuracy: 0.7035\n",
      "Epoch 8/18\n",
      "25/25 [==============================] - 79s 3s/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 2.0705 - val_accuracy: 0.6533\n",
      "Epoch 9/18\n",
      "25/25 [==============================] - 108s 4s/step - loss: 0.0192 - accuracy: 0.9924 - val_loss: 2.0625 - val_accuracy: 0.6332\n",
      "Epoch 10/18\n",
      "25/25 [==============================] - 106s 4s/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 1.7941 - val_accuracy: 0.6734\n",
      "Epoch 11/18\n",
      "25/25 [==============================] - 123s 5s/step - loss: 0.0335 - accuracy: 0.9861 - val_loss: 2.1212 - val_accuracy: 0.6884\n",
      "Epoch 12/18\n",
      "25/25 [==============================] - 132s 5s/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 1.8394 - val_accuracy: 0.6935\n",
      "Epoch 13/18\n",
      "25/25 [==============================] - 133s 5s/step - loss: 0.0503 - accuracy: 0.9849 - val_loss: 2.0590 - val_accuracy: 0.6633\n",
      "Epoch 14/18\n",
      "25/25 [==============================] - 104s 4s/step - loss: 0.1320 - accuracy: 0.9483 - val_loss: 3.4529 - val_accuracy: 0.5829\n",
      "Epoch 15/18\n",
      "25/25 [==============================] - 114s 5s/step - loss: 0.1622 - accuracy: 0.9433 - val_loss: 4.6661 - val_accuracy: 0.5226\n",
      "Epoch 16/18\n",
      "25/25 [==============================] - 77s 3s/step - loss: 0.1193 - accuracy: 0.9584 - val_loss: 3.0771 - val_accuracy: 0.5980\n",
      "Epoch 17/18\n",
      "25/25 [==============================] - 87s 3s/step - loss: 0.0717 - accuracy: 0.9660 - val_loss: 2.2600 - val_accuracy: 0.6432\n",
      "Epoch 18/18\n",
      "25/25 [==============================] - 95s 4s/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 1.7180 - val_accuracy: 0.6734\n",
      "7/7 [==============================] - 4s 496ms/step - loss: 1.7180 - accuracy: 0.6734\n",
      "11\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 94s 4s/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 1.3380 - val_accuracy: 0.7337\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 130s 5s/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 1.3204 - val_accuracy: 0.7236\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 94s 4s/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 1.6209 - val_accuracy: 0.6985\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 95s 4s/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 1.3844 - val_accuracy: 0.6834\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 97s 4s/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 1.2053 - val_accuracy: 0.7387\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 102s 4s/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 1.2609 - val_accuracy: 0.7337\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 93s 4s/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 1.2304 - val_accuracy: 0.7337\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 96s 4s/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 1.2281 - val_accuracy: 0.7437\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 93s 4s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2364 - val_accuracy: 0.7387\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 1.2182 - val_accuracy: 0.7437\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.7337\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 72s 3s/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 1.2953 - val_accuracy: 0.7136\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 75s 3s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.7487\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 74s 3s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2740 - val_accuracy: 0.7538\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.3008 - val_accuracy: 0.7136\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 89s 4s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3075 - val_accuracy: 0.7286\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 71s 3s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2438 - val_accuracy: 0.7337\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 83s 3s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2315 - val_accuracy: 0.7286\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 74s 3s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2781 - val_accuracy: 0.7286\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 79s 3s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.2534 - val_accuracy: 0.7437\n",
      "7/7 [==============================] - 7s 806ms/step - loss: 1.2534 - accuracy: 0.7437\n",
      "12\n",
      "Epoch 1/24\n",
      "25/25 [==============================] - 71s 3s/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 1.4684 - val_accuracy: 0.7186\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 79s 3s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.5744 - val_accuracy: 0.7136\n",
      "Epoch 3/24\n",
      "25/25 [==============================] - 87s 3s/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 1.5098 - val_accuracy: 0.7437\n",
      "Epoch 4/24\n",
      "25/25 [==============================] - 97s 4s/step - loss: 0.0047 - accuracy: 0.9975 - val_loss: 1.4734 - val_accuracy: 0.7136\n",
      "Epoch 5/24\n",
      "25/25 [==============================] - 101s 4s/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 1.3003 - val_accuracy: 0.7286\n",
      "Epoch 6/24\n",
      "25/25 [==============================] - 106s 4s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.7387\n",
      "Epoch 7/24\n",
      "25/25 [==============================] - 109s 4s/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.2533 - val_accuracy: 0.7638\n",
      "Epoch 8/24\n",
      "25/25 [==============================] - 151s 6s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.2210 - val_accuracy: 0.7588\n",
      "Epoch 9/24\n",
      "25/25 [==============================] - 163s 7s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2055 - val_accuracy: 0.7538\n",
      "Epoch 10/24\n",
      "25/25 [==============================] - 147s 6s/step - loss: 0.0043 - accuracy: 0.9975 - val_loss: 1.3195 - val_accuracy: 0.7236\n",
      "Epoch 11/24\n",
      "25/25 [==============================] - 117s 5s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2943 - val_accuracy: 0.7387\n",
      "Epoch 12/24\n",
      "25/25 [==============================] - 105s 4s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.2944 - val_accuracy: 0.7538\n",
      "Epoch 13/24\n",
      "25/25 [==============================] - 110s 4s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.7688\n",
      "Epoch 14/24\n",
      "25/25 [==============================] - 114s 5s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3341 - val_accuracy: 0.7387\n",
      "Epoch 15/24\n",
      "25/25 [==============================] - 79s 3s/step - loss: 0.0229 - accuracy: 0.9975 - val_loss: 1.4204 - val_accuracy: 0.6935\n",
      "Epoch 16/24\n",
      "25/25 [==============================] - 86s 3s/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.4546 - val_accuracy: 0.6985\n",
      "Epoch 17/24\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.0129 - accuracy: 0.9950 - val_loss: 1.5446 - val_accuracy: 0.6935\n",
      "Epoch 18/24\n",
      "25/25 [==============================] - 107s 4s/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 1.6373 - val_accuracy: 0.7286\n",
      "Epoch 19/24\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 1.7807 - val_accuracy: 0.7085\n",
      "Epoch 20/24\n",
      "25/25 [==============================] - 124s 5s/step - loss: 0.0084 - accuracy: 0.9962 - val_loss: 1.7390 - val_accuracy: 0.6382\n",
      "Epoch 21/24\n",
      "25/25 [==============================] - 110s 4s/step - loss: 0.0210 - accuracy: 0.9912 - val_loss: 1.5333 - val_accuracy: 0.6884\n",
      "Epoch 22/24\n",
      "25/25 [==============================] - 132s 5s/step - loss: 0.0243 - accuracy: 0.9950 - val_loss: 1.5930 - val_accuracy: 0.7035\n",
      "Epoch 23/24\n",
      "25/25 [==============================] - 108s 4s/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 1.6388 - val_accuracy: 0.7236\n",
      "Epoch 24/24\n",
      "25/25 [==============================] - 105s 4s/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 2.1595 - val_accuracy: 0.6834\n",
      "7/7 [==============================] - 6s 865ms/step - loss: 2.1595 - accuracy: 0.6834\n",
      "13\n",
      "Loop Completed\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3082 - accuracy: 0.7638\n",
      "Best epoch: 16 with validation accuracy: 0.7638190984725952\n",
      "Test loss: 1.3081632852554321 Test accuracy: 0.7638190984725952\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "best_epoch = None\n",
    "num_epochs = 24\n",
    "count = 0\n",
    "Epoch_list = [1, 2 ,3,4,5,6, 8, 10, 14, 16, 18, 20, 24]\n",
    "HistoryData = []\n",
    "Val_loss_Data = []\n",
    "Val_Acc_Data = []\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "for Loop_Var in Epoch_list:\n",
    "    # Train the model for one epoch\n",
    "    history = model.fit(X_train, Y_train, batch_size=32 , epochs=Loop_Var , verbose=1, validation_data=(X_test, Y_test))\n",
    "    HistoryData.append(history)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_acc = model.evaluate(X_test, Y_test, batch_size=32, verbose=1)\n",
    "    Val_loss_Data.append(val_loss)\n",
    "    Val_Acc_Data.append(val_acc)\n",
    "\n",
    "    # Check if this epoch had the best validation accuracy so far\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = Loop_Var\n",
    "        # Save the model weights for the best epoch\n",
    "        model.save_weights('best_model_weights.h5')\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "print('Loop Completed')\n",
    "# Load the weights for the best epoch\n",
    "model.load_weights('best_model_weights.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=32, verbose=1)\n",
    "\n",
    "print(\"Best epoch: {} with validation accuracy: {}\".format(best_epoch, best_val_acc))\n",
    "print(\"Test loss: {} Test accuracy: {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf51a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dd75e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Windowed: CASIA Anger')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print wavefile \n",
    "Path = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Hamming_Shortened_Cropped/a_C_201-angry-liuchanhg.wav\"\n",
    "signal, sr = librosa.load(Path)\n",
    "librosa.display.waveshow(signal, sr=sr)\n",
    "plt.title(\"Windowed: CASIA Anger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87fd0301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Baseline: CASIA Anger')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print wavefile \n",
    "Path = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Baseline_Shortened_Cropped/a_C_201-angry-liuchanhg.wav\"\n",
    "signal, sr = librosa.load(Path)\n",
    "librosa.display.waveshow(signal, sr=sr)\n",
    "plt.title(\"Baseline: CASIA Anger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc5e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
