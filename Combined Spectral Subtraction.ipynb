{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7f2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #For data manipulation\n",
    "import numpy as np #Separating emotions\n",
    "import glob #For file directories\n",
    "import os\n",
    "import soundfile #Creating sound files\n",
    "import sys\n",
    "import librosa #For audio analysis\n",
    "import librosa.display\n",
    "#import seaborn as sbn\n",
    "import matplotlib.pyplot as plt #Plotting\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report #Showing emotion features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38913c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from scipy.signal import stft, istft\n",
    "\n",
    "# Set the paths to the input and output directories\n",
    "home = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_AugmentNoise_Shortened_Cropped/\"\n",
    "destination = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_AugmentSpectralSubtraction_Shortened_Cropped/\"\n",
    "\n",
    "# Define the parameters for the STFT and spectral subtraction\n",
    "window_size = 1024\n",
    "overlap = int(window_size / 2)\n",
    "alpha = 2\n",
    "\n",
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(home):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Load the audio file\n",
    "        filepath = os.path.join(home, filename)\n",
    "        signal, rate = sf.read(filepath)\n",
    "        \n",
    "        # Compute the STFT of the signal\n",
    "        _, _, stft_signal = stft(signal, nperseg=window_size, noverlap=overlap)\n",
    "        \n",
    "        # Compute the magnitude and phase of the STFT\n",
    "        magnitude = np.abs(stft_signal)\n",
    "        phase = np.angle(stft_signal)\n",
    "        \n",
    "        # Compute the noise estimate using the minimum statistics method\n",
    "        noise_magnitude = np.min(magnitude, axis=1)\n",
    "        \n",
    "        # Compute the noise threshold using the spectral subtraction formula\n",
    "        noise_threshold = alpha * noise_magnitude\n",
    "        \n",
    "        # Apply spectral subtraction to the magnitude of the STFT\n",
    "        subtracted_magnitude = np.maximum(magnitude - noise_threshold.reshape((-1, 1)), 0)\n",
    "        \n",
    "        # Reconstruct the signal from the modified magnitude and original phase\n",
    "        _, filtered_signal = istft(subtracted_magnitude * np.exp(1j * phase), nperseg=window_size, noverlap=overlap)\n",
    "        \n",
    "        # Save the filtered signal to the output directory\n",
    "        output_filename = os.path.join(destination, filename)\n",
    "        sf.write(output_filename, filtered_signal, rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9e6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data = []\n",
    "label = []\n",
    "Path = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_AugmentSpectralSubtraction_Shortened_Cropped/\"\n",
    "files = [f for f in listdir(Path) if isfile(join(Path, f))]\n",
    "for x in files:\n",
    "    filePath = Path + x\n",
    "    label.append(x[0])\n",
    "    signal, sr = librosa.load(filePath, sr=None)\n",
    "    #mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length = 256, n_mfcc = 20) \n",
    "    mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length = 256, n_mfcc = 18) \n",
    "    #mfcc_1d = np.ravel(mfcc)\n",
    "    data.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e15983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 18, 261, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array(data)\n",
    "data.shape\n",
    "X = np.expand_dims(data, axis=3)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867e1b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "label_new = []\n",
    "for i in range(len(label)):\n",
    "    if label[i] == 'n': #Neutral\n",
    "        x=3\n",
    "    elif label[i] == 'h': #Happy\n",
    "        x=0\n",
    "    elif label[i] == 's': #S\n",
    "        x=1\n",
    "    elif label[i] == 'a': #Angry\n",
    "        x = 2\n",
    "    label_new.append(x)\n",
    "\n",
    "print(label_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402aeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ff6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, label_new, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8360cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793, 18, 261, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(x_train)\n",
    "X_test = np.array(x_test)\n",
    "Y_train = np.array(y_train)\n",
    "Y_test = np.array(y_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cfc2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 18, 261, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 18, 261, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 18, 261, 64)       36928     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 18, 261, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 130, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 9, 130, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 9, 130, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 9, 130, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 9, 130, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 9, 130, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 65, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4, 65, 128)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 33280)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               17039872  \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,304,516\n",
      "Trainable params: 17,302,724\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This model gives 62% with 30 mfccs, 75.6% for 18 mfccs\n",
    "# change epochs from 20 - 24\n",
    "model = Sequential()\n",
    "from keras.layers import BatchNormalization\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(18, 261, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0ba967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 131s 5s/step - loss: 1.6821 - accuracy: 0.4288 - val_loss: 6.9679 - val_accuracy: 0.3266\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 112s 4s/step - loss: 0.9480 - accuracy: 0.6015 - val_loss: 6.3772 - val_accuracy: 0.2965\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 109s 4s/step - loss: 0.8370 - accuracy: 0.6784 - val_loss: 2.2256 - val_accuracy: 0.3618\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 109s 4s/step - loss: 0.5688 - accuracy: 0.7844 - val_loss: 5.5206 - val_accuracy: 0.2462\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 109s 4s/step - loss: 0.4793 - accuracy: 0.8159 - val_loss: 1.9658 - val_accuracy: 0.3869\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 108s 4s/step - loss: 0.3466 - accuracy: 0.8739 - val_loss: 1.4372 - val_accuracy: 0.4824\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 110s 4s/step - loss: 0.3036 - accuracy: 0.8916 - val_loss: 1.2648 - val_accuracy: 0.5427\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 108s 4s/step - loss: 0.2102 - accuracy: 0.9218 - val_loss: 1.4602 - val_accuracy: 0.4925\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 98s 4s/step - loss: 0.2320 - accuracy: 0.9231 - val_loss: 2.3887 - val_accuracy: 0.4573\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.1637 - accuracy: 0.9395 - val_loss: 1.7504 - val_accuracy: 0.4774\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 56s 2s/step - loss: 0.1144 - accuracy: 0.9584 - val_loss: 1.5837 - val_accuracy: 0.5578\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 56s 2s/step - loss: 0.0854 - accuracy: 0.9760 - val_loss: 1.6030 - val_accuracy: 0.5528\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 56s 2s/step - loss: 0.0680 - accuracy: 0.9786 - val_loss: 1.5719 - val_accuracy: 0.5327\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.0709 - accuracy: 0.9760 - val_loss: 2.0341 - val_accuracy: 0.5427\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.0501 - accuracy: 0.9823 - val_loss: 1.6565 - val_accuracy: 0.5779\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 56s 2s/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 1.6474 - val_accuracy: 0.5025\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 1.7955 - val_accuracy: 0.5327\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 56s 2s/step - loss: 0.0334 - accuracy: 0.9874 - val_loss: 1.6490 - val_accuracy: 0.5427\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.0368 - accuracy: 0.9899 - val_loss: 1.4825 - val_accuracy: 0.5678\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 57s 2s/step - loss: 0.0167 - accuracy: 0.9987 - val_loss: 1.6271 - val_accuracy: 0.5477\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=32 , epochs=20 , verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958c3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 758ms/step\n",
      "Precision: 0.5974653024681944\n",
      "Recall: 0.5477386934673367\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "# Get the predicted probabilities for the validation set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Compute precision and recall using scikit-learn metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(Y_test, y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219094e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
