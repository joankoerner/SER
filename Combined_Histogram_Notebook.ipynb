{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e34d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #For data manipulation\n",
    "import numpy as np #Separating emotions\n",
    "import glob #For file directories\n",
    "import os\n",
    "import soundfile #Creating sound files\n",
    "import sys\n",
    "import librosa #For audio analysis\n",
    "import librosa.display\n",
    "#import seaborn as sbn\n",
    "import matplotlib.pyplot as plt #Plotting\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report #Showing emotion features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2918b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "home = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Baseline_Shortened_Cropped/\"\n",
    "destination = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Histogram_Shortened_Cropped/\"\n",
    "\n",
    "# Get list of audio files in home folder\n",
    "audio_files = [f for f in os.listdir(home) if f.endswith('.wav')]\n",
    "\n",
    "for file in audio_files:\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(os.path.join(home, file), sr=None)\n",
    "\n",
    "    # Compute histogram of amplitudes\n",
    "    hist, bins = np.histogram(audio, bins=256)\n",
    "\n",
    "    # Compute cumulative distribution function (CDF)\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    # Normalize the CDF\n",
    "    cdf_normalized = cdf / cdf[-1]\n",
    "\n",
    "    # Compute the new audio signal by scaling the amplitudes using the normalized CDF\n",
    "    audio_normalized = np.interp(audio, bins[:-1], cdf_normalized)\n",
    "\n",
    "    # Save the normalized audio signal to destination folder\n",
    "    sf.write(os.path.join(destination, file), audio_normalized, sr, subtype='PCM_16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e664d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data = []\n",
    "label = []\n",
    "Path = \"C:/Users/Lenovo/Documents/3rd Year Project/Dataset/Combined_Histogram_Shortened_Cropped/\"\n",
    "files = [f for f in listdir(Path) if isfile(join(Path, f))]\n",
    "for x in files:\n",
    "    filePath = Path + x\n",
    "    label.append(x[0])\n",
    "    signal, sr = librosa.load(filePath, sr=None)\n",
    "    #mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length = 256, n_mfcc = 20) \n",
    "    mfcc = librosa.feature.mfcc(signal, n_fft=2048, hop_length = 256, n_mfcc = 18) \n",
    "    #mfcc_1d = np.ravel(mfcc)\n",
    "    data.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e125ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 18, 259)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c3734f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 18, 259, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.expand_dims(data, axis=3)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac7791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "label_new = []\n",
    "for i in range(len(label)):\n",
    "    if label[i] == 'n': #Neutral\n",
    "        x=3\n",
    "    elif label[i] == 'h': #Happy\n",
    "        x=0\n",
    "    elif label[i] == 's': #S\n",
    "        x=1\n",
    "    elif label[i] == 'a': #Angry\n",
    "        x = 2\n",
    "    label_new.append(x)\n",
    "\n",
    "print(label_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b7df93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0273270",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, label_new, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0562c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793, 18, 259, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(x_train)\n",
    "X_test = np.array(x_test)\n",
    "Y_train = np.array(y_train)\n",
    "Y_test = np.array(y_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b5592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 18, 259, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 18, 259, 64)      256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 259, 64)       36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 18, 259, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 9, 129, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9, 129, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 129, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 9, 129, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 9, 129, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 9, 129, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 64, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4, 64, 128)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               16777728  \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,042,372\n",
      "Trainable params: 17,040,580\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This model gives 62% with 30 mfccs, 75.6% for 18 mfccs\n",
    "# change epochs from 20 - 24\n",
    "model = Sequential()\n",
    "from keras.layers import BatchNormalization\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(18, 259, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68eff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 96s 4s/step - loss: 1.7935 - accuracy: 0.3821 - val_loss: 14.3372 - val_accuracy: 0.3216\n",
      "7/7 [==============================] - 5s 729ms/step - loss: 14.3372 - accuracy: 0.3216\n",
      "1\n",
      "Epoch 1/2\n",
      "25/25 [==============================] - 87s 3s/step - loss: 1.1327 - accuracy: 0.5675 - val_loss: 9.5361 - val_accuracy: 0.2161\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 80s 3s/step - loss: 1.0022 - accuracy: 0.6179 - val_loss: 3.2527 - val_accuracy: 0.3015\n",
      "7/7 [==============================] - 5s 729ms/step - loss: 3.2527 - accuracy: 0.3015\n",
      "2\n",
      "Epoch 1/3\n",
      "25/25 [==============================] - 89s 4s/step - loss: 0.8072 - accuracy: 0.6810 - val_loss: 1.5843 - val_accuracy: 0.3970\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.6786 - accuracy: 0.7541 - val_loss: 1.9902 - val_accuracy: 0.4322\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 87s 3s/step - loss: 0.6713 - accuracy: 0.7516 - val_loss: 2.0329 - val_accuracy: 0.3668\n",
      "7/7 [==============================] - 5s 711ms/step - loss: 2.0329 - accuracy: 0.3668\n",
      "3\n",
      "Epoch 1/4\n",
      "25/25 [==============================] - 88s 4s/step - loss: 0.4721 - accuracy: 0.8285 - val_loss: 2.1724 - val_accuracy: 0.4171\n",
      "Epoch 2/4\n",
      "25/25 [==============================] - 88s 4s/step - loss: 0.2939 - accuracy: 0.8966 - val_loss: 1.5965 - val_accuracy: 0.4774\n",
      "Epoch 3/4\n",
      "25/25 [==============================] - 88s 4s/step - loss: 0.2526 - accuracy: 0.8991 - val_loss: 1.3343 - val_accuracy: 0.5477\n",
      "Epoch 4/4\n",
      "25/25 [==============================] - 92s 4s/step - loss: 0.1856 - accuracy: 0.9218 - val_loss: 1.4435 - val_accuracy: 0.5025\n",
      "7/7 [==============================] - 5s 736ms/step - loss: 1.4435 - accuracy: 0.5025\n",
      "4\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 90s 4s/step - loss: 0.1445 - accuracy: 0.9496 - val_loss: 1.2195 - val_accuracy: 0.5678\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 89s 4s/step - loss: 0.1009 - accuracy: 0.9685 - val_loss: 1.5402 - val_accuracy: 0.5578\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 88s 4s/step - loss: 0.1272 - accuracy: 0.9533 - val_loss: 1.4512 - val_accuracy: 0.5678\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 88s 4s/step - loss: 0.0819 - accuracy: 0.9748 - val_loss: 1.4434 - val_accuracy: 0.6030\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 89s 4s/step - loss: 0.0558 - accuracy: 0.9861 - val_loss: 1.5150 - val_accuracy: 0.5628\n",
      "7/7 [==============================] - 5s 765ms/step - loss: 1.5150 - accuracy: 0.5628\n",
      "5\n",
      "Epoch 1/6\n",
      "25/25 [==============================] - 115s 5s/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 1.4896 - val_accuracy: 0.6131\n",
      "Epoch 2/6\n",
      "25/25 [==============================] - 99s 4s/step - loss: 0.0465 - accuracy: 0.9861 - val_loss: 1.6296 - val_accuracy: 0.5879\n",
      "Epoch 3/6\n",
      "25/25 [==============================] - 89s 4s/step - loss: 0.0560 - accuracy: 0.9836 - val_loss: 1.9397 - val_accuracy: 0.5930\n",
      "Epoch 4/6\n",
      "25/25 [==============================] - 79s 3s/step - loss: 0.0476 - accuracy: 0.9861 - val_loss: 1.5860 - val_accuracy: 0.5678\n",
      "Epoch 5/6\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0334 - accuracy: 0.9924 - val_loss: 1.5579 - val_accuracy: 0.6131\n",
      "Epoch 6/6\n",
      "25/25 [==============================] - 85s 3s/step - loss: 0.0212 - accuracy: 0.9975 - val_loss: 1.8055 - val_accuracy: 0.5628\n",
      "7/7 [==============================] - 5s 665ms/step - loss: 1.8055 - accuracy: 0.5628\n",
      "6\n",
      "Epoch 1/8\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0204 - accuracy: 0.9962 - val_loss: 1.6036 - val_accuracy: 0.5829\n",
      "Epoch 2/8\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 1.7515 - val_accuracy: 0.5126\n",
      "Epoch 3/8\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: 1.7165 - val_accuracy: 0.5528\n",
      "Epoch 4/8\n",
      "25/25 [==============================] - 82s 3s/step - loss: 0.0171 - accuracy: 0.9975 - val_loss: 1.9735 - val_accuracy: 0.5427\n",
      "Epoch 5/8\n",
      "25/25 [==============================] - 90s 4s/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 1.8744 - val_accuracy: 0.6332\n",
      "Epoch 6/8\n",
      "25/25 [==============================] - 94s 4s/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 1.8266 - val_accuracy: 0.6080\n",
      "Epoch 7/8\n",
      "25/25 [==============================] - 95s 4s/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 1.9074 - val_accuracy: 0.5578\n",
      "Epoch 8/8\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 1.8750 - val_accuracy: 0.6030\n",
      "7/7 [==============================] - 5s 664ms/step - loss: 1.8750 - accuracy: 0.6030\n",
      "7\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0160 - accuracy: 0.9975 - val_loss: 1.8487 - val_accuracy: 0.5477\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 80s 3s/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 1.8555 - val_accuracy: 0.5578\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 90s 4s/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 1.8491 - val_accuracy: 0.5980\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 117s 5s/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 1.9163 - val_accuracy: 0.5779\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 105s 4s/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 2.3344 - val_accuracy: 0.6131\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 101s 4s/step - loss: 0.0202 - accuracy: 0.9975 - val_loss: 2.1673 - val_accuracy: 0.5879\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 107s 4s/step - loss: 0.0258 - accuracy: 0.9937 - val_loss: 2.1469 - val_accuracy: 0.5578\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 104s 4s/step - loss: 0.0431 - accuracy: 0.9823 - val_loss: 2.8371 - val_accuracy: 0.5377\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 94s 4s/step - loss: 0.0560 - accuracy: 0.9773 - val_loss: 2.3579 - val_accuracy: 0.5377\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 98s 4s/step - loss: 0.0421 - accuracy: 0.9887 - val_loss: 2.3320 - val_accuracy: 0.5628\n",
      "7/7 [==============================] - 6s 788ms/step - loss: 2.3320 - accuracy: 0.5628\n",
      "8\n",
      "Epoch 1/14\n",
      "25/25 [==============================] - 99s 4s/step - loss: 0.0318 - accuracy: 0.9937 - val_loss: 2.3080 - val_accuracy: 0.5276\n",
      "Epoch 2/14\n",
      "25/25 [==============================] - 94s 4s/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 2.4515 - val_accuracy: 0.5276\n",
      "Epoch 3/14\n",
      "25/25 [==============================] - 102s 4s/step - loss: 0.0223 - accuracy: 0.9962 - val_loss: 2.5430 - val_accuracy: 0.5176\n",
      "Epoch 4/14\n",
      "25/25 [==============================] - 99s 4s/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 2.2816 - val_accuracy: 0.5327\n",
      "Epoch 5/14\n",
      "25/25 [==============================] - 70s 3s/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.4548 - val_accuracy: 0.5528\n",
      "Epoch 6/14\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.0360 - val_accuracy: 0.5628\n",
      "Epoch 7/14\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 2.1808 - val_accuracy: 0.5377\n",
      "Epoch 8/14\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 2.3746 - val_accuracy: 0.5578\n",
      "Epoch 9/14\n",
      "25/25 [==============================] - 76s 3s/step - loss: 0.0201 - accuracy: 0.9924 - val_loss: 2.4321 - val_accuracy: 0.4975\n",
      "Epoch 10/14\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 2.4639 - val_accuracy: 0.5377\n",
      "Epoch 11/14\n",
      "25/25 [==============================] - 69s 3s/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 2.2846 - val_accuracy: 0.5578\n",
      "Epoch 12/14\n",
      "25/25 [==============================] - 73s 3s/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 2.7264 - val_accuracy: 0.5327\n",
      "Epoch 13/14\n",
      "25/25 [==============================] - 72s 3s/step - loss: 0.0535 - accuracy: 0.9786 - val_loss: 2.9442 - val_accuracy: 0.5377\n",
      "Epoch 14/14\n",
      "25/25 [==============================] - 68s 3s/step - loss: 0.0523 - accuracy: 0.9823 - val_loss: 2.2450 - val_accuracy: 0.5729\n",
      "7/7 [==============================] - 4s 619ms/step - loss: 2.2450 - accuracy: 0.5729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/16\n",
      "25/25 [==============================] - 75s 3s/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 2.4393 - val_accuracy: 0.5879\n",
      "Epoch 2/16\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0472 - accuracy: 0.9823 - val_loss: 2.4116 - val_accuracy: 0.5276\n",
      "Epoch 3/16\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0621 - accuracy: 0.9798 - val_loss: 2.4477 - val_accuracy: 0.5528\n",
      "Epoch 4/16\n",
      "25/25 [==============================] - 65s 3s/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 2.7073 - val_accuracy: 0.5226\n",
      "Epoch 5/16\n",
      "25/25 [==============================] - 65s 3s/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 2.4071 - val_accuracy: 0.5427\n",
      "Epoch 6/16\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 2.2615 - val_accuracy: 0.5528\n",
      "Epoch 7/16\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0238 - accuracy: 0.9912 - val_loss: 2.4357 - val_accuracy: 0.5327\n",
      "Epoch 8/16\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 2.0157 - val_accuracy: 0.5578\n",
      "Epoch 9/16\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 2.3163 - val_accuracy: 0.4925\n",
      "Epoch 10/16\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0327 - accuracy: 0.9861 - val_loss: 2.2707 - val_accuracy: 0.5176\n",
      "Epoch 11/16\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 2.6674 - val_accuracy: 0.4774\n",
      "Epoch 12/16\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 2.3293 - val_accuracy: 0.5377\n",
      "Epoch 13/16\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 2.0611 - val_accuracy: 0.5176\n",
      "Epoch 14/16\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0191 - accuracy: 0.9912 - val_loss: 2.2192 - val_accuracy: 0.5427\n",
      "Epoch 15/16\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 2.7432 - val_accuracy: 0.5578\n",
      "Epoch 16/16\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 2.0346 - val_accuracy: 0.5779\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 2.0346 - accuracy: 0.5779\n",
      "10\n",
      "Epoch 1/18\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 2.1075 - val_accuracy: 0.6332\n",
      "Epoch 2/18\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 2.1835 - val_accuracy: 0.6231\n",
      "Epoch 3/18\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 2.0164 - val_accuracy: 0.5980\n",
      "Epoch 4/18\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 2.1681 - val_accuracy: 0.5829\n",
      "Epoch 5/18\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 1.8774 - val_accuracy: 0.5678\n",
      "Epoch 6/18\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0129 - accuracy: 0.9950 - val_loss: 2.4034 - val_accuracy: 0.4925\n",
      "Epoch 7/18\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.2536 - val_accuracy: 0.5377\n",
      "Epoch 8/18\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 2.1506 - val_accuracy: 0.5678\n",
      "Epoch 9/18\n",
      "25/25 [==============================] - 64s 3s/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 2.5502 - val_accuracy: 0.5528\n",
      "Epoch 10/18\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 2.1123 - val_accuracy: 0.5729\n",
      "Epoch 11/18\n",
      "25/25 [==============================] - 59s 2s/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 2.7451 - val_accuracy: 0.4573\n",
      "Epoch 12/18\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0115 - accuracy: 0.9950 - val_loss: 2.2244 - val_accuracy: 0.5427\n",
      "Epoch 13/18\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 2.6731 - val_accuracy: 0.4975\n",
      "Epoch 14/18\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1853 - val_accuracy: 0.5628\n",
      "Epoch 15/18\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2463 - val_accuracy: 0.5126\n",
      "Epoch 16/18\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.0879 - val_accuracy: 0.5528\n",
      "Epoch 17/18\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 2.2025 - val_accuracy: 0.5930\n",
      "Epoch 18/18\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 2.1336 - val_accuracy: 0.5578\n",
      "7/7 [==============================] - 4s 494ms/step - loss: 2.1336 - accuracy: 0.5578\n",
      "11\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 2.1049 - val_accuracy: 0.6030\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 2.0779 - val_accuracy: 0.6131\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1244 - val_accuracy: 0.6231\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 2.0808 - val_accuracy: 0.5930\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 62s 3s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.9382 - val_accuracy: 0.5729\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9711 - val_accuracy: 0.5628\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.0672 - val_accuracy: 0.5477\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 2.0892 - val_accuracy: 0.5678\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 2.2512 - val_accuracy: 0.5578\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 1.9680 - val_accuracy: 0.5678\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9014 - val_accuracy: 0.5678\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0107 - accuracy: 0.9950 - val_loss: 2.3511 - val_accuracy: 0.5427\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 2.3048 - val_accuracy: 0.5829\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 2.5711 - val_accuracy: 0.5427\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 2.2115 - val_accuracy: 0.5427\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 63s 3s/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 2.2953 - val_accuracy: 0.5628\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 2.1554 - val_accuracy: 0.6181\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0130 - accuracy: 0.9950 - val_loss: 2.1409 - val_accuracy: 0.5729\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 2.0232 - val_accuracy: 0.5829\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.0153 - val_accuracy: 0.6080\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 2.0153 - accuracy: 0.6080\n",
      "12\n",
      "Epoch 1/24\n",
      "25/25 [==============================] - 60s 2s/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 2.3280 - val_accuracy: 0.5427\n",
      "Epoch 2/24\n",
      "25/25 [==============================] - 62s 3s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 2.2642 - val_accuracy: 0.5930\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 60s 2s/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 2.1653 - val_accuracy: 0.5678\n",
      "Epoch 4/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 2.5570 - val_accuracy: 0.5628\n",
      "Epoch 5/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 2.7854 - val_accuracy: 0.5779\n",
      "Epoch 6/24\n",
      "25/25 [==============================] - 62s 3s/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 2.5659 - val_accuracy: 0.5829\n",
      "Epoch 7/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 2.5284 - val_accuracy: 0.5729\n",
      "Epoch 8/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0134 - accuracy: 0.9950 - val_loss: 2.7559 - val_accuracy: 0.5377\n",
      "Epoch 9/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 2.7086 - val_accuracy: 0.5729\n",
      "Epoch 10/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 2.5568 - val_accuracy: 0.5528\n",
      "Epoch 11/24\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 2.9073 - val_accuracy: 0.5678\n",
      "Epoch 12/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 2.8473 - val_accuracy: 0.5427\n",
      "Epoch 13/24\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 2.6636 - val_accuracy: 0.5729\n",
      "Epoch 14/24\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 2.5154 - val_accuracy: 0.5829\n",
      "Epoch 15/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0226 - accuracy: 0.9912 - val_loss: 2.6696 - val_accuracy: 0.5477\n",
      "Epoch 16/24\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 2.4633 - val_accuracy: 0.5879\n",
      "Epoch 17/24\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.0316 - accuracy: 0.9849 - val_loss: 2.9876 - val_accuracy: 0.5025\n",
      "Epoch 18/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0509 - accuracy: 0.9786 - val_loss: 2.2600 - val_accuracy: 0.5779\n",
      "Epoch 19/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 3.5424 - val_accuracy: 0.5327\n",
      "Epoch 20/24\n",
      "25/25 [==============================] - 62s 2s/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 2.5109 - val_accuracy: 0.6231\n",
      "Epoch 21/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 2.3411 - val_accuracy: 0.5729\n",
      "Epoch 22/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 2.6837 - val_accuracy: 0.5578\n",
      "Epoch 23/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 2.7593 - val_accuracy: 0.5176\n",
      "Epoch 24/24\n",
      "25/25 [==============================] - 61s 2s/step - loss: 0.0087 - accuracy: 0.9962 - val_loss: 2.1978 - val_accuracy: 0.5528\n",
      "7/7 [==============================] - 3s 482ms/step - loss: 2.1978 - accuracy: 0.5528\n",
      "13\n",
      "Loop Completed\n",
      "7/7 [==============================] - 3s 489ms/step - loss: 2.0153 - accuracy: 0.6080\n",
      "Best epoch: 20 with validation accuracy: 0.6080402135848999\n",
      "Test loss: 2.015266180038452 Test accuracy: 0.6080402135848999\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "best_epoch = None\n",
    "num_epochs = 24\n",
    "count = 0\n",
    "Epoch_list = [1, 2 ,3,4,5,6, 8, 10, 14, 16, 18, 20, 24]\n",
    "HistoryData = []\n",
    "Val_loss_Data = []\n",
    "Val_Acc_Data = []\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "for Loop_Var in Epoch_list:\n",
    "    # Train the model for one epoch\n",
    "    history = model.fit(X_train, Y_train, batch_size=32 , epochs=Loop_Var , verbose=1, validation_data=(X_test, Y_test))\n",
    "    HistoryData.append(history)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_acc = model.evaluate(X_test, Y_test, batch_size=32, verbose=1)\n",
    "    Val_loss_Data.append(val_loss)\n",
    "    Val_Acc_Data.append(val_acc)\n",
    "\n",
    "    # Check if this epoch had the best validation accuracy so far\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = Loop_Var\n",
    "        # Save the model weights for the best epoch\n",
    "        model.save_weights('best_model_weights.h5')\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "print('Loop Completed')\n",
    "# Load the weights for the best epoch\n",
    "model.load_weights('best_model_weights.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=32, verbose=1)\n",
    "\n",
    "print(\"Best epoch: {} with validation accuracy: {}\".format(best_epoch, best_val_acc))\n",
    "print(\"Test loss: {} Test accuracy: {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0ed685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 785ms/step\n",
      "Precision: 0.6184763088035446\n",
      "Recall: 0.6080402010050251\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "# Get the predicted probabilities for the validation set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Compute precision and recall using scikit-learn metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(Y_test, y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "\n",
    "# Pre-Emphasis\n",
    "# Pre-Emphasis + Windowing: Precision: 77.97% Recall: 75.37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a6ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
